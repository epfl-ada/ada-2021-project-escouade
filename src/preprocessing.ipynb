{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88dce3a8-cccf-426e-aae8-c15ce52e9462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:57:35.617275Z",
     "iopub.status.busy": "2021-11-12T12:57:35.614887Z",
     "iopub.status.idle": "2021-11-12T12:57:37.514756Z",
     "shell.execute_reply": "2021-11-12T12:57:37.514071Z",
     "shell.execute_reply.started": "2021-11-12T12:57:35.617139Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from ressources import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e226aae1-8862-464c-a275-30367b4ac9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:57:37.517395Z",
     "iopub.status.busy": "2021-11-12T12:57:37.516729Z",
     "iopub.status.idle": "2021-11-12T12:57:37.525448Z",
     "shell.execute_reply": "2021-11-12T12:57:37.522145Z",
     "shell.execute_reply.started": "2021-11-12T12:57:37.517349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER = config.RAW_DATA_FOLDER\n",
    "GENERATED_DATA_FOLDER = config.GENERATED_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9408d333-8e96-42a8-aa51-b9cf9a432687",
   "metadata": {},
   "source": [
    "## QUOTEBANK Dataset\n",
    "Exploring and filtering of quotbank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f44d13e-e68e-497c-9579-6dd6cbee6a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:57:58.833110Z",
     "iopub.status.busy": "2021-11-12T12:57:58.832285Z",
     "iopub.status.idle": "2021-11-12T12:57:58.846809Z",
     "shell.execute_reply": "2021-11-12T12:57:58.845665Z",
     "shell.execute_reply.started": "2021-11-12T12:57:58.833057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUOTEBANK_FOLDER = RAW_DATA_FOLDER / \"QUOTEBANK\"\n",
    "file_list = list(QUOTEBANK_FOLDER.glob('*.json.bz2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90dede5-d85d-4cc3-948c-6a36def223a1",
   "metadata": {},
   "source": [
    "### List of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cc7db0-1cbe-4760-bc35-9e764171a8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:58:22.856057Z",
     "iopub.status.busy": "2021-11-12T12:58:22.855717Z",
     "iopub.status.idle": "2021-11-12T12:58:22.910282Z",
     "shell.execute_reply": "2021-11-12T12:58:22.908739Z",
     "shell.execute_reply.started": "2021-11-12T12:58:22.856030Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns quotebank:\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "with pd.read_json(file_list[0], lines=True, compression='bz2', chunksize=1) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        df_quotebank = chunk\n",
    "        break\n",
    "# column list for Quotebank dataset\n",
    "print(f\"\\nColumns quotebank:\\n{df_quotebank.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f3fd2-3d61-48cc-9d6d-d7cc42d9575b",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1105fe-5ced-47cc-8760-7735ff01463b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:58:42.913304Z",
     "iopub.status.busy": "2021-11-12T12:58:42.912758Z",
     "iopub.status.idle": "2021-11-12T12:58:42.997511Z",
     "shell.execute_reply": "2021-11-12T12:58:42.995848Z",
     "shell.execute_reply.started": "2021-11-12T12:58:42.913256Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample quotebank:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-30-000005</td>\n",
       "      <td>... a minimum of 5.25 trillion (plastic) parti...</td>\n",
       "      <td>Marcus Eriksen</td>\n",
       "      <td>[Q55997400]</td>\n",
       "      <td>2018-06-30 07:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>[[Marcus Eriksen, 0.6814], [None, 0.3186]]</td>\n",
       "      <td>[http://www.santacruzsentinel.com/environment-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             quoteID                                          quotation  \\\n",
       "0  2018-06-30-000005  ... a minimum of 5.25 trillion (plastic) parti...   \n",
       "\n",
       "          speaker         qids                date  numOccurrences  \\\n",
       "0  Marcus Eriksen  [Q55997400] 2018-06-30 07:00:00               3   \n",
       "\n",
       "                                       probas  \\\n",
       "0  [[Marcus Eriksen, 0.6814], [None, 0.3186]]   \n",
       "\n",
       "                                                urls phase  \n",
       "0  [http://www.santacruzsentinel.com/environment-...     E  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample for Quotebank dataset\n",
    "print(\"\\nSample quotebank:\\n\")\n",
    "display(df_quotebank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82501c-f8b1-4025-bc98-34956337aad1",
   "metadata": {},
   "source": [
    "### Number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108d582-f81a-4dde-b2b8-fb689e549013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of rows for quotebank dataset\n",
    "chunksize = 10000\n",
    "for file in file_list:\n",
    "    n = 0\n",
    "    print(f\"Processing file {file.name}\")\n",
    "    with pd.read_json(file, lines=True, compression='bz2', chunksize=chunksize) as df_reader:\n",
    "        for chunk in df_reader:\n",
    "            n += len(chunk)\n",
    "            print(n, end = \"\\r\")\n",
    "    \n",
    "    print(f\"{n} rows in {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784e4bc-8ddb-40a9-812f-59a02fd267e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T09:42:24.070186Z",
     "iopub.status.busy": "2021-11-10T09:42:24.067422Z",
     "iopub.status.idle": "2021-11-10T10:39:35.926430Z",
     "shell.execute_reply": "2021-11-10T10:39:35.925677Z",
     "shell.execute_reply.started": "2021-11-10T09:42:24.070126Z"
    },
    "tags": []
   },
   "source": [
    "Output:\n",
    "\n",
    "Processing file quotes-2015.json.bz2</br>\n",
    "20874338 rows in quotes-2015.json.bz2</br>\n",
    "Processing file quotes-2016.json.bz2</br>\n",
    "13862129 rows in quotes-2016.json.bz2</br>\n",
    "Processing file quotes-2017.json.bz2</br>\n",
    "26611588 rows in quotes-2017.json.bz2</br>\n",
    "Processing file quotes-2018.json.bz2</br>\n",
    "27228451 rows in quotes-2018.json.bz2</br>\n",
    "Processing file quotes-2019.json.bz2</br>\n",
    "21763302 rows in quotes-2019.json.bz2</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277edaf6-a865-4113-8b9c-a8517f3604e2",
   "metadata": {},
   "source": [
    "### Filtering out data\n",
    "We decided to keep only the data that contains some keywords in the quote itself or in the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f3935-82bb-4982-a9df-c85dee360c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    path_to_out = GENERATED_DATA_FOLDER / \"QUOTEBANK\"\n",
    "    path_to_out = path_to_out / f\"{file.name.split('.', 1)[0]}-cinema.{file.name.split('.', 1)[1]}\"\n",
    "    with bz2.open(file, 'rb') as in_file:\n",
    "        with bz2.open(path_to_out, 'wb') as out_file:\n",
    "            for instance in in_file:\n",
    "                instance = json.loads(instance)\n",
    "                quote = instance['quotation']\n",
    "                urls = instance['urls']\n",
    "                if 'cinema' in quote or 'film' in quote or 'movie' in quote:\n",
    "                    d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))\n",
    "                elif:\n",
    "                    for url in urls:\n",
    "                        if 'cinema' in url or 'film' in url or 'movie' in url:\n",
    "                            d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7965a-bb85-47ae-9133-64150532d31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c71b02de-8ea8-4feb-94f8-adad56bb2795",
   "metadata": {},
   "source": [
    "## The Internet Movie Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ce504-3d67-49b3-a4fc-c2437b7dd295",
   "metadata": {},
   "source": [
    "### The datasets of the IMDb \n",
    "\n",
    "Each dataset is contained in a gzipped, tab-separated-values (TSV) formatted file in the UTF-8 character set. The first line in each file contains headers that describe what is in each column. A ‘\\N’ is used to denote that a particular field is missing or null for that title/name. The available datasets are as follows:\n",
    "\n",
    "title.akas.tsv.gz - Contains the following information for titles:\n",
    "\n",
    "- titleId (string) - a tconst, an alphanumeric unique identifier of the title\n",
    "- ordering (integer) – a number to uniquely identify rows for a given titleId\n",
    "- title (string) – the localized title\n",
    "- region (string) - the region for this version of the title\n",
    "- language (string) - the language of the title\n",
    "- types (array) - Enumerated set of attributes for this alternative title. One or more of the following: \"alternative\", \"dvd\", \"festival\", \"tv\", \"video\", \"working\", \"original\", \"imdbDisplay\". New values may be added in the future without warning\n",
    "- attributes (array) - Additional terms to describe this alternative title, not enumerated\n",
    "- isOriginalTitle (boolean) – 0: not original title; 1: original title\n",
    "\n",
    "title.basics.tsv.gz - Contains the following information for titles:\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
    "- primaryTitle (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
    "- originalTitle (string) - original title, in the original language\n",
    "- isAdult (boolean) - 0: non-adult title; 1: adult title\n",
    "- startYear (YYYY) – represents the release year of a title. In the case of TV Series, it is the series start year\n",
    "- endYear (YYYY) – TV Series end year. ‘\\N’ for all other title types\n",
    "- runtimeMinutes – primary runtime of the title, in minutes\n",
    "- genres (string array) – includes up to three genres associated with the title\n",
    "\n",
    "title.crew.tsv.gz – Contains the director and writer information for all the titles in IMDb. Fields include:\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- directors (array of nconsts) - director(s) of the given title\n",
    "- writers (array of nconsts) – writer(s) of the given title\n",
    "- title.episode.tsv.gz – Contains the tv episode information. Fields include:\n",
    "- tconst (string) - alphanumeric identifier of episode\n",
    "- parentTconst (string) - alphanumeric identifier of the parent TV Series\n",
    "- seasonNumber (integer) – season number the episode belongs to\n",
    "- episodeNumber (integer) – episode number of the tconst in the TV series\n",
    "\n",
    "title.principals.tsv.gz – Contains the principal cast/crew for titles\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- ordering (integer) – a number to uniquely identify rows for a given titleId\n",
    "- nconst (string) - alphanumeric unique identifier of the name/person\n",
    "- category (string) - the category of job that person was in\n",
    "- job (string) - the specific job title if applicable, else '\\N'\n",
    "- characters (string) - the name of the character played if applicable, else '\\N'\n",
    "\n",
    "title.ratings.tsv.gz – Contains the IMDb rating and votes information for titles\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- averageRating – weighted average of all the individual user ratings\n",
    "- numVotes - number of votes the title has received\n",
    "\n",
    "name.basics.tsv.gz – Contains the following information for names:\n",
    "\n",
    "- nconst (string) - alphanumeric unique identifier of the name/person\n",
    "- primaryName (string)– name by which the person is most often credited\n",
    "- birthYear – in YYYY format\n",
    "- deathYear – in YYYY format if applicable, else '\\N'\n",
    "- primaryProfession (array of strings)– the top-3 professions of the person\n",
    "- knownForTitles (array of tconsts) – titles the person is known for\n",
    "\n",
    "source : https://www.imdb.com/interfaces/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee04dfd-0175-4505-92be-916d8cf9f8e5",
   "metadata": {},
   "source": [
    "### Goal to achieve \n",
    "In this IMDb pre-processing notebook, we want to import the datasets that were defined as being of interest (not all were taken as title.akas.tsv.gz was left behind - sorry title.akas.tsv.gz) and treat them in order to obtain a main dataset, with rows and columns of interest regarding our project. Datasets were merged using the different ids (tconst and nconst) that link tables among them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8f40b-830e-4f42-9d2d-c2964f70255b",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83551db3-1640-428f-9105-e24e39d844e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "principals = './data/title.principals.tsv.gz'\n",
    "names = './data/name.basics.tsv.gz'\n",
    "akas = './data/title.akas.tsv.gz'\n",
    "titles = './data/title.basics.tsv.gz'\n",
    "crew = './data/title.crew.tsv.gz'\n",
    "ratings = './data/title.ratings.tsv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48494e-6e2b-4f2e-9bad-76843d7e01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.read_csv(names, \n",
    "                       compression = \"infer\",\n",
    "                       sep = '\\t',\n",
    "                       na_values = '\\\\N')\n",
    "\n",
    "df_names.drop(columns = ['birthYear', 'deathYear'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c45f1a5-7d7c-43e5-8d96-a3a0dd57f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals = pd.read_csv(principals, \n",
    "                            compression = \"infer\",\n",
    "                            sep = '\\t',\n",
    "                            na_values = '\\\\N')\n",
    "\n",
    "df_principals['name'] = df_principals['nconst'].copy()\n",
    "df_principals['name'] = df_principals['name'].map(df_names.set_index('nconst')['primaryName'])\n",
    "df_principals = df_principals [['tconst', 'ordering', 'nconst', 'name', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd0594-61d1-4cdb-81e5-213bb5a3d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating dataset by keeping only actors\n",
    "actors = ['actor', 'actress']\n",
    "df_principals_actors = df_principals[df_principals.category.isin(actors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17c005-86a9-4f34-922c-f3477857c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new dataframe to transform columns into a dictionary\n",
    "# set index nconst and drop tconst & ordering\n",
    "df_principals_actors_tmp = df_principals_actors.copy()\n",
    "df_principals_actors_tmp = df_principals_actors_tmp.set_index(['tconst', 'ordering'])\n",
    "actors_dictionary = df_principals_actors_tmp.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621ce23-913e-41fa-9074-0a256373085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing with dict values \n",
    "df_principals_actors['actor/actress'] = actors_dictionary.values()\n",
    "df_principals_actors = df_principals_actors.groupby(['tconst']).agg(lambda x: tuple(x)).applymap(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785db96d-808b-4f90-9baa-2d7e31e9815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals_actors = df_principals_actors.drop(columns = ['category', 'ordering', 'nconst', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21053118-6eff-402a-89a7-4f3232c7bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating dataset by keeping the crew and same as before\n",
    "actors = ['actor', 'actress', 'self']\n",
    "df_principals_crew = df_principals[~df_principals['category'].isin(actors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38757ff-75fa-4534-997d-c6974ea5d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals_crew_bis = df_principals_crew.copy()\n",
    "df_principals_crew_bis = df_principals_crew_bis.set_index(['tconst', 'ordering'])\n",
    "crew_dictionary = df_principals_crew_bis.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7a76c-8092-4bd3-a90c-98f90c1c2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals_crew['crew'] = crew_dictionary.values()\n",
    "df_principals_crew= df_principals_crew.groupby(['tconst']).agg(lambda x: tuple(x)).applymap(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b44f2-76b6-430d-a06c-6c8c7c20a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals_crew = df_principals_crew.drop(columns = ['category', 'ordering', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ccf6f-7cd7-43aa-b7a6-cdd8e695f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = pd.read_csv(titles, \n",
    "            compression = \"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')\n",
    "\n",
    "df_titles.drop(columns = ['endYear', 'isAdult', 'primaryTitle'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ea15a-87e7-43bd-8dd0-9841b084a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew = pd.read_csv(crew, \n",
    "            compression=\"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26816d03-9692-4dd0-a07d-bce4f8ac9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(ratings, \n",
    "            compression=\"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71492096-a836-4a13-b24c-9ed733296669",
   "metadata": {},
   "source": [
    "### Merging the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d34926-934b-449e-8d85-10c92e186936",
   "metadata": {},
   "source": [
    "Here, we are merging df_titles, df_crew and df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fea8d660-4c7e-45ac-92b3-e8c01c95be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging df_crew and df_titles to have a dataframe containing movies and there respective crew\n",
    "merged = pd.merge(df_titles, df_crew, on = 'tconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bc13ae8-4cb9-4dee-bddf-8d7e63f2db8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['short', 'movie', 'tvEpisode', 'tvSeries', 'tvShort', 'tvMovie',\n",
       "       'tvMiniSeries', 'tvSpecial', 'video', 'videoGame', 'tvPilot'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking types considered in the database\n",
    "merged['titleType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a95e4c32-980e-4836-aaa4-ed4c4a7c5cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe contains now 593343 rows\n"
     ]
    }
   ],
   "source": [
    "#keeping only rows concerning movies\n",
    "merged.drop(merged.loc[merged['titleType'] != 'movie'].index, inplace=True)\n",
    "\n",
    "print(f'the dataframe contains now {len(merged)} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe6ee40c-5c9e-4b9d-b813-c83ff91ea0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing some fancy rearranging\n",
    "merged = merged.drop(columns = ['titleType'])\n",
    "merged = merged.rename(columns = {'startYear' : 'year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73ce5a65-9caa-468a-91e4-158c5f7558f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(df_principals_actors, on = 'tconst', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0d6d017-f614-4e29-8618-28fe4b879690",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(df_principals_crew, on = 'tconst', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31e4417a-b64d-4ab7-b231-d981bb7c7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding ratings from df_ratings (now we have movies and there title, the crew associated and the ratings)\n",
    "merged = merged.merge(df_ratings, on = 'tconst', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aee8cd01-75c4-4ffe-b0ae-a324a5e19213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>year</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>directors</th>\n",
       "      <th>writers</th>\n",
       "      <th>actor/actress</th>\n",
       "      <th>crew</th>\n",
       "      <th>averageRating_x</th>\n",
       "      <th>numVotes_x</th>\n",
       "      <th>averageRating_y</th>\n",
       "      <th>numVotes_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000502</td>\n",
       "      <td>Bohemios</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nm0063413</td>\n",
       "      <td>nm0063413,nm0657268,nm0675388</td>\n",
       "      <td>[{'nconst': 'nm0215752', 'name': 'Antonio del ...</td>\n",
       "      <td>[{'nconst': 'nm0063413', 'name': 'Ricardo de B...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000574</td>\n",
       "      <td>The Story of the Kelly Gang</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>70</td>\n",
       "      <td>Action,Adventure,Biography</td>\n",
       "      <td>nm0846879</td>\n",
       "      <td>nm0846879</td>\n",
       "      <td>[{'nconst': 'nm0846887', 'name': 'Elizabeth Ta...</td>\n",
       "      <td>[{'nconst': 'nm0675239', 'name': 'Orrie Perry'...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>736.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000591</td>\n",
       "      <td>L'enfant prodigue</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Drama</td>\n",
       "      <td>nm0141150</td>\n",
       "      <td>nm0141150</td>\n",
       "      <td>[{'nconst': 'nm0906197', 'name': 'Georges Wagu...</td>\n",
       "      <td>[{'nconst': 'nm0141150', 'name': 'Michel Carré...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000615</td>\n",
       "      <td>Robbery Under Arms</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>nm0533958</td>\n",
       "      <td>nm0092809,nm0533958</td>\n",
       "      <td>[{'nconst': 'nm3071427', 'name': 'Jim Gerald',...</td>\n",
       "      <td>[{'nconst': 'nm0533958', 'name': 'Charles MacM...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000630</td>\n",
       "      <td>Amleto</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>nm0143333</td>\n",
       "      <td>nm0000636</td>\n",
       "      <td>[{'nconst': 'nm0624446', 'name': 'Fernanda Neg...</td>\n",
       "      <td>[{'nconst': 'nm0143333', 'name': 'Mario Caseri...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593338</th>\n",
       "      <td>tt9916622</td>\n",
       "      <td>Rodolpho Teóphilo - O Legado de um Pioneiro</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>57</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>nm9272491,nm9272490</td>\n",
       "      <td>nm9272490,nm9272491</td>\n",
       "      <td>[{'nconst': 'nm9272513', 'name': 'Oldair Soare...</td>\n",
       "      <td>[{'nconst': 'nm9272492', 'name': 'Nilson Filho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593339</th>\n",
       "      <td>tt9916680</td>\n",
       "      <td>De la ilusión al desconcierto: cine colombiano...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>nm0652213</td>\n",
       "      <td>nm0652213,nm10538576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'nconst': 'nm4762061', 'name': 'Cristian Cor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593340</th>\n",
       "      <td>tt9916706</td>\n",
       "      <td>Dankyavar Danka</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>nm7764440</td>\n",
       "      <td>nm7933903</td>\n",
       "      <td>[{'nconst': 'nm9722080', 'name': 'Suvarna Kale...</td>\n",
       "      <td>[{'nconst': 'nm7764440', 'name': 'Kanchan Naya...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593341</th>\n",
       "      <td>tt9916730</td>\n",
       "      <td>6 Gunn</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nm10538612</td>\n",
       "      <td>nm10538612</td>\n",
       "      <td>[{'nconst': 'nm6096005', 'name': 'Devadhar Arc...</td>\n",
       "      <td>[{'nconst': 'nm10538612', 'name': 'Kiran Gawad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593342</th>\n",
       "      <td>tt9916754</td>\n",
       "      <td>Chico Albuquerque - Revelações</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>49</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>nm8349149,nm9272490</td>\n",
       "      <td>nm8349149,nm9272490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'nconst': 'nm9275317', 'name': 'Fábio Ferraz...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593343 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst                                      originalTitle    year  \\\n",
       "0       tt0000502                                           Bohemios  1905.0   \n",
       "1       tt0000574                        The Story of the Kelly Gang  1906.0   \n",
       "2       tt0000591                                  L'enfant prodigue  1907.0   \n",
       "3       tt0000615                                 Robbery Under Arms  1907.0   \n",
       "4       tt0000630                                             Amleto  1908.0   \n",
       "...           ...                                                ...     ...   \n",
       "593338  tt9916622        Rodolpho Teóphilo - O Legado de um Pioneiro  2015.0   \n",
       "593339  tt9916680  De la ilusión al desconcierto: cine colombiano...  2007.0   \n",
       "593340  tt9916706                                    Dankyavar Danka  2013.0   \n",
       "593341  tt9916730                                             6 Gunn  2017.0   \n",
       "593342  tt9916754                     Chico Albuquerque - Revelações  2013.0   \n",
       "\n",
       "       runtimeMinutes                      genres            directors  \\\n",
       "0                 100                         NaN            nm0063413   \n",
       "1                  70  Action,Adventure,Biography            nm0846879   \n",
       "2                  90                       Drama            nm0141150   \n",
       "3                 NaN                       Drama            nm0533958   \n",
       "4                 NaN                       Drama            nm0143333   \n",
       "...               ...                         ...                  ...   \n",
       "593338             57                 Documentary  nm9272491,nm9272490   \n",
       "593339            100                 Documentary            nm0652213   \n",
       "593340            NaN                      Comedy            nm7764440   \n",
       "593341            116                         NaN           nm10538612   \n",
       "593342             49                 Documentary  nm8349149,nm9272490   \n",
       "\n",
       "                              writers  \\\n",
       "0       nm0063413,nm0657268,nm0675388   \n",
       "1                           nm0846879   \n",
       "2                           nm0141150   \n",
       "3                 nm0092809,nm0533958   \n",
       "4                           nm0000636   \n",
       "...                               ...   \n",
       "593338            nm9272490,nm9272491   \n",
       "593339           nm0652213,nm10538576   \n",
       "593340                      nm7933903   \n",
       "593341                     nm10538612   \n",
       "593342            nm8349149,nm9272490   \n",
       "\n",
       "                                            actor/actress  \\\n",
       "0       [{'nconst': 'nm0215752', 'name': 'Antonio del ...   \n",
       "1       [{'nconst': 'nm0846887', 'name': 'Elizabeth Ta...   \n",
       "2       [{'nconst': 'nm0906197', 'name': 'Georges Wagu...   \n",
       "3       [{'nconst': 'nm3071427', 'name': 'Jim Gerald',...   \n",
       "4       [{'nconst': 'nm0624446', 'name': 'Fernanda Neg...   \n",
       "...                                                   ...   \n",
       "593338  [{'nconst': 'nm9272513', 'name': 'Oldair Soare...   \n",
       "593339                                                NaN   \n",
       "593340  [{'nconst': 'nm9722080', 'name': 'Suvarna Kale...   \n",
       "593341  [{'nconst': 'nm6096005', 'name': 'Devadhar Arc...   \n",
       "593342                                                NaN   \n",
       "\n",
       "                                                     crew  averageRating_x  \\\n",
       "0       [{'nconst': 'nm0063413', 'name': 'Ricardo de B...              4.5   \n",
       "1       [{'nconst': 'nm0675239', 'name': 'Orrie Perry'...              6.1   \n",
       "2       [{'nconst': 'nm0141150', 'name': 'Michel Carré...              5.2   \n",
       "3       [{'nconst': 'nm0533958', 'name': 'Charles MacM...              4.5   \n",
       "4       [{'nconst': 'nm0143333', 'name': 'Mario Caseri...              3.8   \n",
       "...                                                   ...              ...   \n",
       "593338  [{'nconst': 'nm9272492', 'name': 'Nilson Filho...              NaN   \n",
       "593339  [{'nconst': 'nm4762061', 'name': 'Cristian Cor...              NaN   \n",
       "593340  [{'nconst': 'nm7764440', 'name': 'Kanchan Naya...              NaN   \n",
       "593341  [{'nconst': 'nm10538612', 'name': 'Kiran Gawad...              NaN   \n",
       "593342  [{'nconst': 'nm9275317', 'name': 'Fábio Ferraz...              NaN   \n",
       "\n",
       "        numVotes_x  averageRating_y  numVotes_y  \n",
       "0             14.0              4.5        14.0  \n",
       "1            736.0              6.1       736.0  \n",
       "2             16.0              5.2        16.0  \n",
       "3             23.0              4.5        23.0  \n",
       "4             23.0              3.8        23.0  \n",
       "...            ...              ...         ...  \n",
       "593338         NaN              NaN         NaN  \n",
       "593339         NaN              NaN         NaN  \n",
       "593340         NaN              NaN         NaN  \n",
       "593341         NaN              NaN         NaN  \n",
       "593342         NaN              NaN         NaN  \n",
       "\n",
       "[593343 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.drop(columns = ['nconst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65171ad0-72ec-41ae-9741-6676c92c0263",
   "metadata": {},
   "source": [
    "Saving into pickle (but a bit useless for now) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5a4cd6a-88f6-4d13-8892-7a791ee16058",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_pickle('main_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7c233-3989-4857-8115-fe316cbfa424",
   "metadata": {},
   "source": [
    "### Saving main dataframe into json\n",
    "Here, we simply save the dataframe in json format. json was chosen of behalf of csv format, to match the quotebank dataset which is also in json and to more easily play with the dicts created on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50674eb5-c766-4993-88e2-151c9cfd85ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-6d32313a9fc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"IMDb.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0md_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'records'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bz2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0mindent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2352\u001b[1;33m         return json.to_json(\n\u001b[0m\u001b[0;32m   2353\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "with open(\"IMDb.json.bz2\", 'wb') as d_file:\n",
    "    d_file.write(merged.to_json(orient = 'records', compression='bz2', lines = True).encode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4e189-f4b7-4855-879b-f19c7c97f660",
   "metadata": {},
   "source": [
    "### Prepare another dict for further work with IMDb.json\n",
    "Creating a dict that will be use to end the pre-processing of this database. As some columns of the previous main dataframe are still imperfect (directors and writers columns have nconst values instead of names), we're creating a dict that simply link nconst with names. It will be also useful to handle the Wikidata dataset which contains the same ids (nconst) as found in the IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edea1e3e-8c01-416d-ac50-5d0544beb9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-9eb7e8aca6e4>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nconst['id'] = df_nconst['nconst'].copy()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nm0000001</th>\n",
       "      <td>nm0000001</td>\n",
       "      <td>Fred Astaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nm0000002</th>\n",
       "      <td>nm0000002</td>\n",
       "      <td>Lauren Bacall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nm0000003</th>\n",
       "      <td>nm0000003</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nm0000004</th>\n",
       "      <td>nm0000004</td>\n",
       "      <td>John Belushi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nm0000005</th>\n",
       "      <td>nm0000005</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nm9993714</th>\n",
       "      <td>nm9993714</td>\n",
       "      <td>Romeo del Rosario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nm9993716</th>\n",
       "      <td>nm9993716</td>\n",
       "      <td>Essias Loberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nm9993717</th>\n",
       "      <td>nm9993717</td>\n",
       "      <td>Harikrishnan Rajan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nm9993718</th>\n",
       "      <td>nm9993718</td>\n",
       "      <td>Aayush Nair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nm9993719</th>\n",
       "      <td>nm9993719</td>\n",
       "      <td>Andre Hill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11357768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              nconst                name\n",
       "id                                      \n",
       "nm0000001  nm0000001        Fred Astaire\n",
       "nm0000002  nm0000002       Lauren Bacall\n",
       "nm0000003  nm0000003     Brigitte Bardot\n",
       "nm0000004  nm0000004        John Belushi\n",
       "nm0000005  nm0000005      Ingmar Bergman\n",
       "...              ...                 ...\n",
       "nm9993714  nm9993714   Romeo del Rosario\n",
       "nm9993716  nm9993716       Essias Loberg\n",
       "nm9993717  nm9993717  Harikrishnan Rajan\n",
       "nm9993718  nm9993718         Aayush Nair\n",
       "nm9993719  nm9993719          Andre Hill\n",
       "\n",
       "[11357768 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dict with nconst as keys and names as values\n",
    "df_nconst = df_names[['nconst', 'primaryName']]\n",
    "df_nconst['id'] = df_nconst['nconst'].copy()\n",
    "df_nconst = df_nconst.rename(columns = {'primaryName' : 'name'})\n",
    "df_nconst.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc219388-6107-4b16-b602-95be0cfc8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = df_nconst.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7ec3c09-dfbc-4085-bd15-3fa7b017c1dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-980e2e90d94a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nconst_names.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('nconst_names.json', 'w') as file:\n",
    "    json.dump(dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
