{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88dce3a8-cccf-426e-aae8-c15ce52e9462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:57:35.617275Z",
     "iopub.status.busy": "2021-11-12T12:57:35.614887Z",
     "iopub.status.idle": "2021-11-12T12:57:37.514756Z",
     "shell.execute_reply": "2021-11-12T12:57:37.514071Z",
     "shell.execute_reply.started": "2021-11-12T12:57:35.617139Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from ressources import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e226aae1-8862-464c-a275-30367b4ac9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:57:37.517395Z",
     "iopub.status.busy": "2021-11-12T12:57:37.516729Z",
     "iopub.status.idle": "2021-11-12T12:57:37.525448Z",
     "shell.execute_reply": "2021-11-12T12:57:37.522145Z",
     "shell.execute_reply.started": "2021-11-12T12:57:37.517349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER = config.RAW_DATA_FOLDER\n",
    "GENERATED_DATA_FOLDER = config.GENERATED_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9408d333-8e96-42a8-aa51-b9cf9a432687",
   "metadata": {},
   "source": [
    "## QUOTEBANK Dataset\n",
    "Exploring and filtering of quotbank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f44d13e-e68e-497c-9579-6dd6cbee6a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:57:58.833110Z",
     "iopub.status.busy": "2021-11-12T12:57:58.832285Z",
     "iopub.status.idle": "2021-11-12T12:57:58.846809Z",
     "shell.execute_reply": "2021-11-12T12:57:58.845665Z",
     "shell.execute_reply.started": "2021-11-12T12:57:58.833057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUOTEBANK_FOLDER = RAW_DATA_FOLDER / \"QUOTEBANK\"\n",
    "file_list = list(QUOTEBANK_FOLDER.glob('*.json.bz2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90dede5-d85d-4cc3-948c-6a36def223a1",
   "metadata": {},
   "source": [
    "### List of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cc7db0-1cbe-4760-bc35-9e764171a8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:58:22.856057Z",
     "iopub.status.busy": "2021-11-12T12:58:22.855717Z",
     "iopub.status.idle": "2021-11-12T12:58:22.910282Z",
     "shell.execute_reply": "2021-11-12T12:58:22.908739Z",
     "shell.execute_reply.started": "2021-11-12T12:58:22.856030Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns quotebank:\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "with pd.read_json(file_list[0], lines=True, compression='bz2', chunksize=1) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        df_quotebank = chunk\n",
    "        break\n",
    "# column list for Quotebank dataset\n",
    "print(f\"\\nColumns quotebank:\\n{df_quotebank.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f3fd2-3d61-48cc-9d6d-d7cc42d9575b",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1105fe-5ced-47cc-8760-7735ff01463b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:58:42.913304Z",
     "iopub.status.busy": "2021-11-12T12:58:42.912758Z",
     "iopub.status.idle": "2021-11-12T12:58:42.997511Z",
     "shell.execute_reply": "2021-11-12T12:58:42.995848Z",
     "shell.execute_reply.started": "2021-11-12T12:58:42.913256Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample quotebank:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-30-000005</td>\n",
       "      <td>... a minimum of 5.25 trillion (plastic) parti...</td>\n",
       "      <td>Marcus Eriksen</td>\n",
       "      <td>[Q55997400]</td>\n",
       "      <td>2018-06-30 07:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>[[Marcus Eriksen, 0.6814], [None, 0.3186]]</td>\n",
       "      <td>[http://www.santacruzsentinel.com/environment-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             quoteID                                          quotation  \\\n",
       "0  2018-06-30-000005  ... a minimum of 5.25 trillion (plastic) parti...   \n",
       "\n",
       "          speaker         qids                date  numOccurrences  \\\n",
       "0  Marcus Eriksen  [Q55997400] 2018-06-30 07:00:00               3   \n",
       "\n",
       "                                       probas  \\\n",
       "0  [[Marcus Eriksen, 0.6814], [None, 0.3186]]   \n",
       "\n",
       "                                                urls phase  \n",
       "0  [http://www.santacruzsentinel.com/environment-...     E  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample for Quotebank dataset\n",
    "print(\"\\nSample quotebank:\\n\")\n",
    "display(df_quotebank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82501c-f8b1-4025-bc98-34956337aad1",
   "metadata": {},
   "source": [
    "### Number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108d582-f81a-4dde-b2b8-fb689e549013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of rows for quotebank dataset\n",
    "chunksize = 10000\n",
    "for file in file_list:\n",
    "    n = 0\n",
    "    print(f\"Processing file {file.name}\")\n",
    "    with pd.read_json(file, lines=True, compression='bz2', chunksize=chunksize) as df_reader:\n",
    "        for chunk in df_reader:\n",
    "            n += len(chunk)\n",
    "            print(n, end = \"\\r\")\n",
    "    \n",
    "    print(f\"{n} rows in {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784e4bc-8ddb-40a9-812f-59a02fd267e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T09:42:24.070186Z",
     "iopub.status.busy": "2021-11-10T09:42:24.067422Z",
     "iopub.status.idle": "2021-11-10T10:39:35.926430Z",
     "shell.execute_reply": "2021-11-10T10:39:35.925677Z",
     "shell.execute_reply.started": "2021-11-10T09:42:24.070126Z"
    },
    "tags": []
   },
   "source": [
    "Output:\n",
    "\n",
    "Processing file quotes-2015.json.bz2</br>\n",
    "20874338 rows in quotes-2015.json.bz2</br>\n",
    "Processing file quotes-2016.json.bz2</br>\n",
    "13862129 rows in quotes-2016.json.bz2</br>\n",
    "Processing file quotes-2017.json.bz2</br>\n",
    "26611588 rows in quotes-2017.json.bz2</br>\n",
    "Processing file quotes-2018.json.bz2</br>\n",
    "27228451 rows in quotes-2018.json.bz2</br>\n",
    "Processing file quotes-2019.json.bz2</br>\n",
    "21763302 rows in quotes-2019.json.bz2</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277edaf6-a865-4113-8b9c-a8517f3604e2",
   "metadata": {},
   "source": [
    "### Filtering out data\n",
    "We decided to keep only the data that contains some keywords in the quote itself or in the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f3935-82bb-4982-a9df-c85dee360c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    path_to_out = GENERATED_DATA_FOLDER / \"QUOTEBANK\"\n",
    "    path_to_out = path_to_out / f\"{file.name.split('.', 1)[0]}-cinema.{file.name.split('.', 1)[1]}\"\n",
    "    with bz2.open(file, 'rb') as in_file:\n",
    "        with bz2.open(path_to_out, 'wb') as out_file:\n",
    "            for instance in in_file:\n",
    "                instance = json.loads(instance)\n",
    "                quote = instance['quotation']\n",
    "                urls = instance['urls']\n",
    "                if 'cinema' in quote or 'film' in quote or 'movie' in quote:\n",
    "                    d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))\n",
    "                elif:\n",
    "                    for url in urls:\n",
    "                        if 'cinema' in url or 'film' in url or 'movie' in url:\n",
    "                            d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7965a-bb85-47ae-9133-64150532d31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c71b02de-8ea8-4feb-94f8-adad56bb2795",
   "metadata": {},
   "source": [
    "## The Internet Movie Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ce504-3d67-49b3-a4fc-c2437b7dd295",
   "metadata": {},
   "source": [
    "### The datasets of the IMDb \n",
    "\n",
    "Each dataset is contained in a gzipped, tab-separated-values (TSV) formatted file in the UTF-8 character set. The first line in each file contains headers that describe what is in each column. A ‘\\N’ is used to denote that a particular field is missing or null for that title/name. The available datasets are as follows:\n",
    "\n",
    "title.akas.tsv.gz - Contains the following information for titles:\n",
    "\n",
    "- titleId (string) - a tconst, an alphanumeric unique identifier of the title\n",
    "- ordering (integer) – a number to uniquely identify rows for a given titleId\n",
    "- title (string) – the localized title\n",
    "- region (string) - the region for this version of the title\n",
    "- language (string) - the language of the title\n",
    "- types (array) - Enumerated set of attributes for this alternative title. One or more of the following: \"alternative\", \"dvd\", \"festival\", \"tv\", \"video\", \"working\", \"original\", \"imdbDisplay\". New values may be added in the future without warning\n",
    "- attributes (array) - Additional terms to describe this alternative title, not enumerated\n",
    "- isOriginalTitle (boolean) – 0: not original title; 1: original title\n",
    "\n",
    "title.basics.tsv.gz - Contains the following information for titles:\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
    "- primaryTitle (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
    "- originalTitle (string) - original title, in the original language\n",
    "- isAdult (boolean) - 0: non-adult title; 1: adult title\n",
    "- startYear (YYYY) – represents the release year of a title. In the case of TV Series, it is the series start year\n",
    "- endYear (YYYY) – TV Series end year. ‘\\N’ for all other title types\n",
    "- runtimeMinutes – primary runtime of the title, in minutes\n",
    "- genres (string array) – includes up to three genres associated with the title\n",
    "\n",
    "title.crew.tsv.gz – Contains the director and writer information for all the titles in IMDb. Fields include:\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- directors (array of nconsts) - director(s) of the given title\n",
    "- writers (array of nconsts) – writer(s) of the given title\n",
    "- title.episode.tsv.gz – Contains the tv episode information. Fields include:\n",
    "- tconst (string) - alphanumeric identifier of episode\n",
    "- parentTconst (string) - alphanumeric identifier of the parent TV Series\n",
    "- seasonNumber (integer) – season number the episode belongs to\n",
    "- episodeNumber (integer) – episode number of the tconst in the TV series\n",
    "\n",
    "title.principals.tsv.gz – Contains the principal cast/crew for titles\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- ordering (integer) – a number to uniquely identify rows for a given titleId\n",
    "- nconst (string) - alphanumeric unique identifier of the name/person\n",
    "- category (string) - the category of job that person was in\n",
    "- job (string) - the specific job title if applicable, else '\\N'\n",
    "- characters (string) - the name of the character played if applicable, else '\\N'\n",
    "\n",
    "title.ratings.tsv.gz – Contains the IMDb rating and votes information for titles\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- averageRating – weighted average of all the individual user ratings\n",
    "- numVotes - number of votes the title has received\n",
    "\n",
    "name.basics.tsv.gz – Contains the following information for names:\n",
    "\n",
    "- nconst (string) - alphanumeric unique identifier of the name/person\n",
    "- primaryName (string)– name by which the person is most often credited\n",
    "- birthYear – in YYYY format\n",
    "- deathYear – in YYYY format if applicable, else '\\N'\n",
    "- primaryProfession (array of strings)– the top-3 professions of the person\n",
    "- knownForTitles (array of tconsts) – titles the person is known for\n",
    "\n",
    "source : https://www.imdb.com/interfaces/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee04dfd-0175-4505-92be-916d8cf9f8e5",
   "metadata": {},
   "source": [
    "### Goal to achieve \n",
    "In this IMDb pre-processing notebook, we want to import the datasets that were defined as being of interest (not all were taken as title.akas.tsv.gz was left behind - sorry title.akas.tsv.gz) and treat them in order to obtain a main dataset, with rows and columns of interest regarding our project. Datasets were merged using the different ids (tconst and nconst) that link tables among them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8f40b-830e-4f42-9d2d-c2964f70255b",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83551db3-1640-428f-9105-e24e39d844e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "principals = './data/title.principals.tsv.gz'\n",
    "names = './data/name.basics.tsv.gz'\n",
    "akas = './data/title.akas.tsv.gz'\n",
    "titles = './data/title.basics.tsv.gz'\n",
    "crew = './data/title.crew.tsv.gz'\n",
    "ratings = './data/title.ratings.tsv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48494e-6e2b-4f2e-9bad-76843d7e01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.read_csv(names, \n",
    "            compression = \"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')\n",
    "\n",
    "df_names.drop(columns = ['birthYear', 'deathYear'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c45f1a5-7d7c-43e5-8d96-a3a0dd57f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals = pd.read_csv(principals, \n",
    "            compression = \"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')\n",
    "\n",
    "df_principals['name'] = df_principals['nconst'].copy()\n",
    "df_principals['name'] = df_principals['name'].map(df_names.set_index('nconst')['primaryName'])\n",
    "df_principals = df_principals [['tconst', 'ordering', 'nconst', 'name', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd0594-61d1-4cdb-81e5-213bb5a3d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating dataset by keeping only actors\n",
    "actors = ['actor', 'actress']\n",
    "df_principals_actors = df_principals[df_principals.category.isin(actors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17c005-86a9-4f34-922c-f3477857c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new dataframe to transform columns into a dictionary\n",
    "df_principals_actors_bis = df_principals_actors.copy()\n",
    "df_principals_actors_bis = df_principals_actors_bis.set_index(['tconst', 'ordering'])\n",
    "dict = df_principals_actors_bis.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621ce23-913e-41fa-9074-0a256373085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing with dict values \n",
    "df_principals_actors['actor/actress'] = dict.values()\n",
    "df_principals_actors = df_principals_actors.groupby(['tconst']).agg(lambda x: tuple(x)).applymap(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785db96d-808b-4f90-9baa-2d7e31e9815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals_actors = df_principals_actors.drop(columns = ['category', 'ordering', 'nconst', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21053118-6eff-402a-89a7-4f3232c7bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating dataset by keeping the crew and same as before\n",
    "actors = ['actor', 'actress', 'self']\n",
    "df_principals_crew = df_principals[~df_principals['category'].isin(actors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38757ff-75fa-4534-997d-c6974ea5d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals_crew_bis = df_principals_crew.copy()\n",
    "df_principals_crew_bis = df_principals_crew_bis.set_index(['tconst', 'ordering'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f445bfa6-bdd8-4d07-83cd-5d0b38fbd07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = df_principals_crew_bis.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7a76c-8092-4bd3-a90c-98f90c1c2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals_crew['crew'] = dict.values()\n",
    "df_principals_crew= df_principals_crew.groupby(['tconst']).agg(lambda x: tuple(x)).applymap(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b44f2-76b6-430d-a06c-6c8c7c20a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals_crew = df_principals_crew.drop(columns = ['category', 'ordering', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ccf6f-7cd7-43aa-b7a6-cdd8e695f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = pd.read_csv(titles, \n",
    "            compression = \"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')\n",
    "\n",
    "df_titles.drop(columns = ['endYear', 'isAdult', 'primaryTitle'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ea15a-87e7-43bd-8dd0-9841b084a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew = pd.read_csv(crew, \n",
    "            compression=\"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26816d03-9692-4dd0-a07d-bce4f8ac9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(ratings, \n",
    "            compression=\"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71492096-a836-4a13-b24c-9ed733296669",
   "metadata": {},
   "source": [
    "### Merging the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d34926-934b-449e-8d85-10c92e186936",
   "metadata": {},
   "source": [
    "Here, we are merging df_titles, df_crew and df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fea8d660-4c7e-45ac-92b3-e8c01c95be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging df_crew and df_titles to have a dataframe containing movies and there respective crew\n",
    "merged = pd.merge(df_titles, df_crew, on = 'tconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bc13ae8-4cb9-4dee-bddf-8d7e63f2db8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['short', 'movie', 'tvEpisode', 'tvSeries', 'tvShort', 'tvMovie',\n",
       "       'tvMiniSeries', 'tvSpecial', 'video', 'videoGame', 'tvPilot'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking types considered in the database\n",
    "merged['titleType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a95e4c32-980e-4836-aaa4-ed4c4a7c5cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe contains now 593343 rows\n"
     ]
    }
   ],
   "source": [
    "#keeping only rows concerning movies\n",
    "merged.drop(merged.loc[merged['titleType'] != 'movie'].index, inplace=True)\n",
    "\n",
    "print(f'the dataframe contains now {len(merged)} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe6ee40c-5c9e-4b9d-b813-c83ff91ea0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing some fancy rearranging\n",
    "merged = merged.drop(columns = ['titleType'])\n",
    "merged = merged.rename(columns = {'startYear' : 'year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73ce5a65-9caa-468a-91e4-158c5f7558f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(df_principals_actors, on = 'tconst', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0d6d017-f614-4e29-8618-28fe4b879690",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(df_principals_crew, on = 'tconst', how = 'left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
