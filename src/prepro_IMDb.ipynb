{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import spacy\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from ressources import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER = config.RAW_DATA_FOLDER\n",
    "GENERATED_DATA_FOLDER = str(config.GENERATED_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "principals = '../data/title.principals.tsv.gz'\n",
    "names = '../data/name.basics.tsv.gz'\n",
    "akas = '../data/title.akas.tsv.gz'\n",
    "titles = '../data/title.basics.tsv.gz'\n",
    "crew = '../data/title.crew.tsv.gz'\n",
    "ratings = '../data/title.ratings.tsv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Internet Movie Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets of the IMDb \n",
    "\n",
    "The Internet Movie Database is an open source database that contains informations regarding movies, TV series, TV movies and even video games. This database which is hosted on a website, is used to rates and simply record characteristics of each features present. The dataset can be found on the IMDB.com website, and it is described as follows :\n",
    "\n",
    "Each dataset is contained in a gzipped, tab-separated-values (TSV) formatted file in the UTF-8 character set. The first line in each file contains headers that describe what is in each column. A ‘\\N’ is used to denote that a particular field is missing or null for that title/name. The available datasets are as follows:\n",
    "\n",
    "title.akas.tsv.gz - Contains the following information for titles:\n",
    "\n",
    "- titleId (string) - a tconst, an alphanumeric unique identifier of the title\n",
    "- ordering (integer) – a number to uniquely identify rows for a given titleId\n",
    "- title (string) – the localized title\n",
    "- region (string) - the region for this version of the title\n",
    "- language (string) - the language of the title\n",
    "- types (array) - Enumerated set of attributes for this alternative title. One or more of the following: \"alternative\", \"dvd\", \"festival\", \"tv\", \"video\", \"working\", \"original\", \"imdbDisplay\". New values may be added in the future without warning\n",
    "- attributes (array) - Additional terms to describe this alternative title, not enumerated\n",
    "- isOriginalTitle (boolean) – 0: not original title; 1: original title\n",
    "\n",
    "title.basics.tsv.gz - Contains the following information for titles:\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
    "- primaryTitle (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
    "- originalTitle (string) - original title, in the original language\n",
    "- isAdult (boolean) - 0: non-adult title; 1: adult title\n",
    "- startYear (YYYY) – represents the release year of a title. In the case of TV Series, it is the series start year\n",
    "- endYear (YYYY) – TV Series end year. ‘\\N’ for all other title types\n",
    "- runtimeMinutes – primary runtime of the title, in minutes\n",
    "- genres (string array) – includes up to three genres associated with the title\n",
    "\n",
    "title.crew.tsv.gz – Contains the director and writer information for all the titles in IMDb. Fields include:\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- directors (array of nconsts) - director(s) of the given title\n",
    "- writers (array of nconsts) – writer(s) of the given title\n",
    "- title.episode.tsv.gz – Contains the tv episode information. Fields include:\n",
    "- tconst (string) - alphanumeric identifier of episode\n",
    "- parentTconst (string) - alphanumeric identifier of the parent TV Series\n",
    "- seasonNumber (integer) – season number the episode belongs to\n",
    "- episodeNumber (integer) – episode number of the tconst in the TV series\n",
    "\n",
    "title.principals.tsv.gz – Contains the principal cast/crew for titles\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- ordering (integer) – a number to uniquely identify rows for a given titleId\n",
    "- nconst (string) - alphanumeric unique identifier of the name/person\n",
    "- category (string) - the category of job that person was in\n",
    "- job (string) - the specific job title if applicable, else '\\N'\n",
    "- characters (string) - the name of the character played if applicable, else '\\N'\n",
    "\n",
    "title.ratings.tsv.gz – Contains the IMDb rating and votes information for titles\n",
    "\n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- averageRating – weighted average of all the individual user ratings\n",
    "- numVotes - number of votes the title has received\n",
    "\n",
    "name.basics.tsv.gz – Contains the following information for names:\n",
    "\n",
    "- nconst (string) - alphanumeric unique identifier of the name/person\n",
    "- primaryName (string)– name by which the person is most often credited\n",
    "- birthYear – in YYYY format\n",
    "- deathYear – in YYYY format if applicable, else '\\N'\n",
    "- primaryProfession (array of strings)– the top-3 professions of the person\n",
    "- knownForTitles (array of tconsts) – titles the person is known for\n",
    "\n",
    "source : https://www.imdb.com/interfaces/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal to achieve \n",
    "In this IMDb pre-processing notebook, we want to import the datasets that were defined as being of interest (not all were taken as title.akas.tsv.gz was left behind - sorry title.akas.tsv.gz) and treat them in order to obtain a main dataset, with rows and columns of interest regarding our project. As described before, the database doesn't concern only movies, so the main dataset will have to be filtered as we will not consider series - for example. \n",
    "\n",
    "Datasets were merged using the different ids (tconst and nconst) that link tables among them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets\n",
    "In this section, we are importing the datasets of interest as dataframes. Datasets are compressed into .gz archives and None values where directly replaced when importing them, in order to facilitate the processing.\n",
    "\n",
    "Nota Bene : as the datasets are of size around 300MB each, it is not possible to push them in the git repository (limited to 100MB). Datasets where opened locally and therefore the paths below can't be run.\n",
    "\n",
    "The link to download the datasets is : https://datasets.imdbws.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.read_csv(names, \n",
    "                       compression = \"infer\",\n",
    "                       sep = '\\t',\n",
    "                       na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principals = pd.read_csv(principals, \n",
    "                            compression = \"infer\",\n",
    "                            sep = '\\t',\n",
    "                            na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\celin\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_titles = pd.read_csv(titles, \n",
    "            compression = \"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew = pd.read_csv(crew, \n",
    "            compression=\"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(ratings, \n",
    "            compression=\"infer\",\n",
    "            sep = '\\t',\n",
    "            na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Starting with df_name : \n",
    "Here, it is only needed to drop columns that would not be in use for the project, which are the birth year and death year of each people present in the IMDb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.drop(columns = ['birthYear', 'deathYear'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Then with df_principals : this dataframe needs more processing as we want to transform values of some column into a dict. Indeed, as there are multiple actors, actresses or crew members for each movies in the database, the dataframe will be separate into two parts (respectively actors/actresses and crew members). Each columsn of each rows of the separated dataframes are then aggregated into one dictionary - one dictionary containing, as example, the id/ the name/ the category of the concerned person. Finally, people are merged together into a list of dictionaries, to obtain a final dataframe which has one row per movie containing all crew members, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of the dataframe column 'nconst'\n",
    "df_principals['name'] = df_principals['nconst'].copy()\n",
    "\n",
    "#mapping nconst values of the dataframe with names that are present in the df_names dataframe (based on the id nconst)\n",
    "df_principals['name'] = df_principals['name'].map(df_names.set_index('nconst')['primaryName'])\n",
    "df_principals = df_principals [['tconst', 'ordering', 'nconst', 'name', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if everything was mapped :\n",
    "None in df_principals['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-520412db787b>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_principals_actors['actor/actress'] = actors_dictionary.values()\n"
     ]
    }
   ],
   "source": [
    "# separating dataset by keeping rows where category = actors or actresses \n",
    "actors = ['actor', 'actress']\n",
    "df_principals_actors = df_principals[df_principals.category.isin(actors)]\n",
    "\n",
    "# creating a new dataframe to transform columns into a dictionary\n",
    "# set index nconst and drop tconst & ordering\n",
    "df_principals_actors_tmp = df_principals_actors.copy()\n",
    "df_principals_actors_tmp = df_principals_actors_tmp.set_index(['tconst', 'ordering'])\n",
    "actors_dictionary = df_principals_actors_tmp.to_dict('index')\n",
    "\n",
    "# replacing with dict values \n",
    "df_principals_actors['actor/actress'] = actors_dictionary.values()\n",
    "\n",
    "# as there are multiple rows for each movie (as there are multiple crew member), aggregating rows by movie's id and so creating a list of dict\n",
    "# on the column actor/actress\n",
    "df_principals_actors = df_principals_actors.groupby(['tconst']).agg(lambda x: tuple(x)).applymap(list).reset_index()\n",
    "df_principals_actors = df_principals_actors.drop(columns = ['category', 'ordering', 'nconst', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-aa59e9b5650e>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_principals_crew['crew'] = crew_dictionary.values()\n"
     ]
    }
   ],
   "source": [
    "# separating dataset by keeping the rows concerning the crew and same as before\n",
    "actors = ['actor', 'actress', 'self']\n",
    "df_principals_crew = df_principals[~df_principals['category'].isin(actors)]\n",
    "\n",
    "# creating a new dataframe to transform columns into a dictionary\n",
    "# set index nconst and drop tconst & ordering\n",
    "df_principals_crew_tmp = df_principals_crew.copy()\n",
    "df_principals_crew_tmp = df_principals_crew_tmp.set_index(['tconst', 'ordering'])\n",
    "crew_dictionary = df_principals_crew_tmp.to_dict('index')\n",
    "\n",
    "# replacing with dict values \n",
    "df_principals_crew['crew'] = crew_dictionary.values()\n",
    "\n",
    "# as there are multiple rows for each movie (as there are multiple crew member), aggregating rows by movie's id and so creating a list of dict\n",
    "# on the column actor/actress\n",
    "df_principals_crew= df_principals_crew.groupby(['tconst']).agg(lambda x: tuple(x)).applymap(list).reset_index()\n",
    "df_principals_crew = df_principals_crew.drop(columns = ['category', 'ordering', 'name', 'nconst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Processing the dataframe df_titles, by only dropping some columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.drop(columns = ['endYear', 'isAdult', 'primaryTitle'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are merging all datasets into one main dataset, by simple aggregating columns based on the 'tconst' id, which are ids of movies. But first, rows have to be filtered to keep only the ones which concern movies !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging df_crew and df_titles to have a dataframe containing movies and there respective crew\n",
    "merged = pd.merge(df_titles, df_crew, on = 'tconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['short', 'movie', 'tvEpisode', 'tvSeries', 'tvShort', 'tvMovie',\n",
       "       'tvMiniSeries', 'tvSpecial', 'video', 'videoGame', 'tvPilot'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking types considered in the database\n",
    "merged['titleType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe contains now 593343 rows\n"
     ]
    }
   ],
   "source": [
    "# keeping only rows concerning movies\n",
    "merged.drop(merged.loc[merged['titleType'] != 'movie'].index, inplace = True)\n",
    "print(f'the dataframe contains now {len(merged)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the genre 'Documentary' as it doesn't have an interest for our research on movies and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe contains now 505028 rows\n"
     ]
    }
   ],
   "source": [
    "genres = ['Documentary', 'Biography,Documentary', 'Biography']\n",
    "merged.drop(merged.loc[merged['genres'].isin(genres)].index, inplace = True)\n",
    "print(f'the dataframe contains now {len(merged)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains ~500k movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing some fancy rearranging\n",
    "merged = merged.drop(columns = ['titleType'])\n",
    "merged = merged.rename(columns = {'startYear' : 'year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(df_principals_actors, on = 'tconst', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(df_principals_crew, on = 'tconst', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding ratings from df_ratings (now we have movies and there title, the crew associated and the ratings)\n",
    "merged = merged.merge(df_ratings, on = 'tconst', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving main dataframe into json and pickle\n",
    "Here, we simply save the dataframe in json format. json was chosen of behalf of csv format, to match the quotebank dataset which is also in json and to more easily play with the dicts created on the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving into pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('IMDb_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(merged, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving into json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open('IMDb.json.bz2', 'wb') as d_file:\n",
    "    d_file.write(merged.to_json(orient = 'records', lines = True).encode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing another dict for further work with IMDb.json\n",
    "Creating a dict that will be used to end the pre-processing of this database. As some columns of the previous main dataframe are still imperfect (directors and writers columns have nconst values instead of names), we're creating a dict that simply link nconst with names. It will be also useful to handle the Wikidata dataset which contains the same ids (nconst) as found in the IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dict with nconst as keys and names as values\n",
    "df_nconst = df_names[['nconst', 'primaryName']]\n",
    "df_nconst = df_nconst.rename(columns = {'primaryName' : 'name'})\n",
    "df_nconst.set_index('nconst')\n",
    "\n",
    "nconst_names = df_nconst.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dict into pickle for futur use\n",
    "with open('nconst_names.pickle', 'wb') as handle:\n",
    "    pickle.dump(nconst_names, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the json file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the IMDb json file is processed to convert 'nconst' ids to names by mapping actor/actress and crew columns with the pickle created previously. Information related to each actor/actress and crew members are put into a dictionary where the key is the nconst id. Director and writer columns are put into the crew column, in the condition if it is not already in, then the columns are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nconst = pd.read_pickle('nconst_names.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FILE = 'IMDb.json.bz2'\n",
    "PATH_TO_OUT = 'IMDb_clean.json.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json file as dictionary with json.load\n",
    "with bz2.open(PATH_TO_FILE, 'rb') as s_file:\n",
    "    with bz2.open(PATH_TO_OUT, 'wb') as d_file:\n",
    "    # We could also use 'ab' mode to append to an existing file\n",
    "        person_name_list = []\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance)\n",
    "            \n",
    "            # handle None values\n",
    "            if instance['actor/actress']:\n",
    "                actors = {}\n",
    "                for e in instance['actor/actress']:\n",
    "                    # rearranging the column values into a dictionary\n",
    "                    actors[e['nconst']] = {'name' : e['name'], 'role' : [e['category']]}  \n",
    "                    # appending names for further creation of a list \n",
    "                    person_name_list.append(e['name'])\n",
    "                instance['actor/actress'] = actors\n",
    "\n",
    "            if instance['crew']:\n",
    "                crew = {}\n",
    "                for e in instance['crew']:\n",
    "                    crew[e['nconst']] = {'name' : e['name'], 'role' : [e['category']]}    \n",
    "                instance['crew'] = crew\n",
    "\n",
    "                if instance['directors'] :\n",
    "                    # instances are in the form of a string of nconst separated with ','\n",
    "                    instance['directors'] = instance['directors'].split(',')\n",
    "                    for e in instance['directors'] :\n",
    "                        try :    \n",
    "                            if e not in instance['crew']:\n",
    "                                instance['crew'][e] = {'name' : nconst[e], 'role' : ['director']} \n",
    "                            elif 'director' not in instance['crew'][e]['role']:\n",
    "                                instance['crew'][e]['role'].append('director')\n",
    "                        # raising an exception when a nconst is not present on the nconst pickle \n",
    "                        # name marked as unknown\n",
    "                        except KeyError :\n",
    "                            instance['crew'][e] = {'name' : 'unknown'}                          \n",
    "\n",
    "                if instance['writers'] :\n",
    "                    instance['writers'] = instance['writers'].split(',')\n",
    "                    for e in instance['writers'] :\n",
    "                        try :\n",
    "                            if e not in instance['crew']:\n",
    "                                instance['crew'][e] = {'name' : nconst[e], 'role' : ['writer']} \n",
    "                            elif 'writer' not in instance['crew'][e]['role']:\n",
    "                                instance['crew'][e]['role'].append('writer')\n",
    "                        except KeyError :\n",
    "                            instance['crew'][e] = {'name' : 'unknown'}                          \n",
    "\n",
    "                for name in instance['crew'].values() :\n",
    "                    person_name_list.append(name['name'])\n",
    "            # dropping useless columns\n",
    "            instance.pop('directors', 'writers')\n",
    "            # for a fine print :\n",
    "            # print(json.dumps(instance, indent = 4))            \n",
    "            d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a number of pickles for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of lists and pickle are created to perform analysis on the other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_pickle('IMDb_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a sub dataframe with columns related to ratings\n",
    "df_ratings = main_df[['tconst', 'numVotes', 'averageRating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pickle with ratings information\n",
    "with open(GENERATED_DATA_FOLDER + '/IMDB/df_ratings.pickle', 'wb') as f: \n",
    "    pickle.dump(df_ratings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of the 500'000 movie titles in the IMDb\n",
    "film_name = list(main_df['originalTitle'])\n",
    "with open(GENERATED_DATA_FOLDER + '/IMDB/film_name_list.pickle', 'wb') as f: \n",
    "    pickle.dump(film_name, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of all the people \n",
    "person_name_list = list(set(person_name_list))\n",
    "with open(GENERATED_DATA_FOLDER + '/IMDB/person_name_list.pickle', 'wb') as f: \n",
    "    pickle.dump(person_name_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another sub dataframe transformed into a dict that map {tconst : title}\n",
    "df_tconst = main_df[['tconst', 'originalTitle']]\n",
    "df_tconst = df_tconst.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving it in a pickle\n",
    "with open('tconst_title.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_tconst, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tconst_list = []\n",
    "nconst_list = []\n",
    "\n",
    "# re-opening the IMDb_clean json to obtain lists of tconst and nconst\n",
    "with bz2.open(PATH_TO_OUT, 'rb') as s_file:\n",
    "    for instance in s_file :\n",
    "        instance = json.loads(instance)\n",
    "        tconst_list.append(instance['tconst'])\n",
    "        \n",
    "        if instance['actor/actress']:\n",
    "            for e in instance['actor/actress']:\n",
    "                nconst_list.append(e)\n",
    "        if instance['crew']:\n",
    "            for e in instance['crew']:\n",
    "                nconst_list.append(e)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GENERATED_DATA_FOLDER + '/IMDB/tconst_list.pickle', 'wb') as f: \n",
    "    pickle.dump(tconst_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GENERATED_DATA_FOLDER + '/IMDB/nconst_list.pickle', 'wb') as f: \n",
    "    pickle.dump(nconst_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tconst = pd.read_pickle(GENERATED_DATA_FOLDER + '/IMDB/tconst_list.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_list = list(set(main_df['originalTitle']))\n",
    "with open(GENERATED_DATA_FOLDER + '/IMDB/title_list.pickle', 'wb') as f: \n",
    "    pickle.dump(film_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening Wikidata and adding gender to the IMDb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKIDATA_GENDER_DICT = 'nconst_enriched_dict.json.bz2'\n",
    "IMDB_GENDER = 'IMDb_gender.json.bz2'\n",
    "IMDB_FINAL = 'IMDb_final.json.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>year</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>writers</th>\n",
       "      <th>actor/actress</th>\n",
       "      <th>crew</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000502</td>\n",
       "      <td>Bohemios</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>None</td>\n",
       "      <td>[nm0063413, nm0657268, nm0675388]</td>\n",
       "      <td>{'nm0215752': {'name': 'Antonio del Pozo', 'ro...</td>\n",
       "      <td>{'nm0063413': {'name': 'Ricardo de Baños', 'ro...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000574</td>\n",
       "      <td>The Story of the Kelly Gang</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Action,Adventure,Biography</td>\n",
       "      <td>[nm0846879]</td>\n",
       "      <td>{'nm0846887': {'name': 'Elizabeth Tait', 'role...</td>\n",
       "      <td>{'nm0675239': {'name': 'Orrie Perry', 'role': ...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000591</td>\n",
       "      <td>L'enfant prodigue</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>[nm0141150]</td>\n",
       "      <td>{'nm0906197': {'name': 'Georges Wague', 'role'...</td>\n",
       "      <td>{'nm0141150': {'name': 'Michel Carré', 'role':...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000615</td>\n",
       "      <td>Robbery Under Arms</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>[nm0092809, nm0533958]</td>\n",
       "      <td>{'nm3071427': {'name': 'Jim Gerald', 'role': [...</td>\n",
       "      <td>{'nm0533958': {'name': 'Charles MacMahon', 'ro...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000630</td>\n",
       "      <td>Amleto</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>[nm0000636]</td>\n",
       "      <td>{'nm0624446': {'name': 'Fernanda Negri Pouget'...</td>\n",
       "      <td>{'nm0143333': {'name': 'Mario Caserini', 'role...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst                originalTitle    year  runtimeMinutes  \\\n",
       "0  tt0000502                     Bohemios  1905.0           100.0   \n",
       "1  tt0000574  The Story of the Kelly Gang  1906.0            70.0   \n",
       "2  tt0000591            L'enfant prodigue  1907.0            90.0   \n",
       "3  tt0000615           Robbery Under Arms  1907.0             NaN   \n",
       "4  tt0000630                       Amleto  1908.0             NaN   \n",
       "\n",
       "                       genres                            writers  \\\n",
       "0                        None  [nm0063413, nm0657268, nm0675388]   \n",
       "1  Action,Adventure,Biography                        [nm0846879]   \n",
       "2                       Drama                        [nm0141150]   \n",
       "3                       Drama             [nm0092809, nm0533958]   \n",
       "4                       Drama                        [nm0000636]   \n",
       "\n",
       "                                       actor/actress  \\\n",
       "0  {'nm0215752': {'name': 'Antonio del Pozo', 'ro...   \n",
       "1  {'nm0846887': {'name': 'Elizabeth Tait', 'role...   \n",
       "2  {'nm0906197': {'name': 'Georges Wague', 'role'...   \n",
       "3  {'nm3071427': {'name': 'Jim Gerald', 'role': [...   \n",
       "4  {'nm0624446': {'name': 'Fernanda Negri Pouget'...   \n",
       "\n",
       "                                                crew  averageRating  numVotes  \n",
       "0  {'nm0063413': {'name': 'Ricardo de Baños', 'ro...            4.5      14.0  \n",
       "1  {'nm0675239': {'name': 'Orrie Perry', 'role': ...            6.1     736.0  \n",
       "2  {'nm0141150': {'name': 'Michel Carré', 'role':...            5.2      16.0  \n",
       "3  {'nm0533958': {'name': 'Charles MacMahon', 'ro...            4.5      23.0  \n",
       "4  {'nm0143333': {'name': 'Mario Caserini', 'role...            3.8      23.0  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb = pd.read_json(PATH_TO_OUT, compression = 'bz2', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('IMDb_clean.pickle', 'wb') as f: \n",
    "    pickle.dump(df_imdb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wikidata json here contains : the nconst of person, its gender and the date of birth. The gender id is replaced by the label 'male', 'female' or 'other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_json(WIKIDATA_GENDER_DICT, compression = 'bz2', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = [\"Q6581097\", \"Q6581072\"]\n",
    "wiki['genderlabel'] = wiki['gender'].replace({\"Q6581097\" : 'male', \"Q6581072\" : 'female'})\n",
    "wiki.loc[~wiki['gender'].isin(gender)] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the genderlabel column was well replaced and contains only 'male', 'female' and 'other' values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female' 'other']\n"
     ]
    }
   ],
   "source": [
    "print(wiki.genderlabel.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dict that maps {nconst : genderlabel} and adding the gender in the IMDB_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = dict(zip(wiki.nconst, wiki.genderlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open(PATH_TO_OUT, 'rb') as s_file:\n",
    "    with bz2.open(IMDB_GENDER, 'wb') as d_file:\n",
    "        e = 0\n",
    "        for instance in s_file :\n",
    "            instance = json.loads(instance.decode(\"utf-8\"))\n",
    "            if instance[\"crew\"]:\n",
    "                for ID, value in instance[\"crew\"].items():\n",
    "                    try:\n",
    "                        value[\"gender\"] = gender_dict[ID]\n",
    "                    except KeyError:\n",
    "                        e += 1\n",
    "                        value[\"gender\"] = None\n",
    "            if instance[\"actor/actress\"]:\n",
    "                for ID, value in instance[\"actor/actress\"].items():\n",
    "                    try :\n",
    "                        value[\"gender\"] = gender_dict[ID]    \n",
    "                    except KeyError:\n",
    "                        e += 1\n",
    "                        value[\"gender\"] = None\n",
    "                    \n",
    "            #print(json.dumps(instance, indent = 4))            \n",
    "            d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open(IMDB_GENDER, 'rb') as s_file:\n",
    "    with bz2.open(IMDB_FINAL, 'wb') as d_file:\n",
    "        for instance in s_file :\n",
    "            instance = json.loads(instance.decode(\"utf-8\"))\n",
    "            \n",
    "            # instancing a dictionary\n",
    "            gender = {e: 0 for e in ['male', 'female']}\n",
    "            \n",
    "            if instance[\"crew\"]:\n",
    "                # navigating the dicts in the rows and adding a gender key for each person in the crew, same is done for the actress/actors\n",
    "                for key, person in instance[\"crew\"].items():\n",
    "                    if person[\"gender\"] and person[\"gender\"] != 'other':\n",
    "                        gender[person[\"gender\"]] += 1\n",
    "                    \n",
    "            if instance[\"actor/actress\"]:\n",
    "                for key, person in instance[\"actor/actress\"].items():\n",
    "                    if person[\"gender\"] and person[\"gender\"] != 'other':\n",
    "                        gender[person[\"gender\"]] += 1\n",
    "            \n",
    "            tot = sum(gender.values())\n",
    "            if tot != 0:\n",
    "                # calculates the percentage of female/male gender for each movie, ignoring the 'other' values\n",
    "                gender_pct = {e: gender[e]/tot for e in ['male', 'female']}\n",
    "            else :\n",
    "                gender_pct = None\n",
    "            # creates a new column on the dataframe that contains the gender percentage in a form of a dictionary\n",
    "            instance[\"gender_pct\"] = gender_pct\n",
    "            d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_json(IMDB_FINAL, compression = 'bz2', lines = True)\n",
    "df_final.drop(columns = ['writers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then filtering the dataframe by keeping the movies that were found on quotebank's quotes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "tconst_quotebank = pd.read_pickle('tconst_usefull_list.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final[df_final['tconst'].isin(tconst_quotebank)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the length of the final dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe contains 6583 rows, which is what we want\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataframe contains {len(df_final)} rows, which is what we want')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a \\~final\\~ pickle of the IMDb, that will be used on Q3 mostly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('IMDb_final.pickle', 'wb') as f: \n",
    "    pickle.dump(df_final, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
