{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from ressources import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER = config.RAW_DATA_FOLDER\n",
    "GENERATED_DATA_FOLDER = config.GENERATED_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitarization(word_list):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    word_list_san = []   \n",
    "    for film in word_list:\n",
    "        doc_film_name = nlp(film)\n",
    "        tokens = [token.text for token in doc_film_name]\n",
    "        result = \" \".join(tokens)\n",
    "        word_list_san.append(result)\n",
    "    return word_list_san"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUOTEBANK Dataset\n",
    "Exploring and filtering of quotbank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUOTEBANK_FOLDER = RAW_DATA_FOLDER / \"QUOTEBANK\"\n",
    "file_list = list(QUOTEBANK_FOLDER.glob('*.json.bz2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-70e055b31ab6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bz2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mdf_quotebank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# column list for Quotebank dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with pd.read_json(file_list[0], lines=True, compression='bz2', chunksize=1) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        df_quotebank = chunk\n",
    "        break\n",
    "# column list for Quotebank dataset\n",
    "print(f\"\\nColumns quotebank:\\n{df_quotebank.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample quotebank:\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_quotebank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bbb653380afb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sample for Quotebank dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nSample quotebank:\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_quotebank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_quotebank' is not defined"
     ]
    }
   ],
   "source": [
    "# Sample for Quotebank dataset\n",
    "print(\"\\nSample quotebank:\\n\")\n",
    "display(df_quotebank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of rows for quotebank dataset\n",
    "chunksize = 10000\n",
    "for file in file_list:\n",
    "    n = 0\n",
    "    print(f\"Processing file {file.name}\")\n",
    "    with pd.read_json(file, lines=True, compression='bz2', chunksize=chunksize) as df_reader:\n",
    "        for chunk in df_reader:\n",
    "            n += len(chunk)\n",
    "            print(n, end = \"\\r\")\n",
    "    \n",
    "    print(f\"{n} rows in {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T09:42:24.070186Z",
     "iopub.status.busy": "2021-11-10T09:42:24.067422Z",
     "iopub.status.idle": "2021-11-10T10:39:35.926430Z",
     "shell.execute_reply": "2021-11-10T10:39:35.925677Z",
     "shell.execute_reply.started": "2021-11-10T09:42:24.070126Z"
    },
    "tags": []
   },
   "source": [
    "Output:\n",
    "\n",
    "Processing file quotes-2015.json.bz2</br>\n",
    "20874338 rows in quotes-2015.json.bz2</br>\n",
    "Processing file quotes-2016.json.bz2</br>\n",
    "13862129 rows in quotes-2016.json.bz2</br>\n",
    "Processing file quotes-2017.json.bz2</br>\n",
    "26611588 rows in quotes-2017.json.bz2</br>\n",
    "Processing file quotes-2018.json.bz2</br>\n",
    "27228451 rows in quotes-2018.json.bz2</br>\n",
    "Processing file quotes-2019.json.bz2</br>\n",
    "21763302 rows in quotes-2019.json.bz2</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out data\n",
    "We decided to keep only the data that contains some keywords in the quote itself or in the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    path_to_out = GENERATED_DATA_FOLDER / \"QUOTEBANK\"\n",
    "    path_to_out = path_to_out / f\"{file.name.split('.', 1)[0]}-cinema.{file.name.split('.', 1)[1]}\"\n",
    "    with bz2.open(file, 'rb') as in_file:\n",
    "        with bz2.open(path_to_out, 'wb') as out_file:\n",
    "            for instance in in_file:\n",
    "                instance = json.loads(instance)\n",
    "                quote = instance['quotation']\n",
    "                urls = instance['urls']\n",
    "                if 'cinema' in quote or 'film' in quote or 'movie' in quote:\n",
    "                    d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))\n",
    "                elif:\n",
    "                    for url in urls:\n",
    "                        if 'cinema' in url or 'film' in url or 'movie' in url:\n",
    "                            d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouvrir quotebank 2018 et rajouter les colonnes et l'enregistrer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open wikidata dictionary\n",
    "with open('../generated/WIKIDATA/dict_wikidata_people.pickle', 'rb') as f: \n",
    "     dict_wikidata_people = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Q23', {'label': 'George Washington', 'genderlabel': 'male', 'dob_std': '22.02.1732'}), ('Q42', {'label': 'Douglas Adams', 'genderlabel': 'male', 'dob_std': '11.03.1952'}), ('Q1868', {'label': 'Paul Otlet', 'genderlabel': 'male', 'dob_std': '23.08.1868'})])\n",
      "{'Q23': {'label': 'George Washington', 'genderlabel': 'male', 'dob_std': '22.02.1732'}, 'Q42': {'label': 'Douglas Adams', 'genderlabel': 'male', 'dob_std': '11.03.1952'}, 'Q1868': {'label': 'Paul Otlet', 'genderlabel': 'male', 'dob_std': '23.08.1868'}}\n",
      "Q23\n",
      "male\n",
      "22.02.1732\n",
      "Q42\n",
      "male\n",
      "11.03.1952\n",
      "Q1868\n",
      "male\n",
      "23.08.1868\n"
     ]
    }
   ],
   "source": [
    "#teste pour faire la fonction en bas (a supprimer si plus besoins)\n",
    "next(iter(dict_wikidata_people.values())) #acces to values\n",
    "next(iter(dict_wikidata_people)) #acces to key\n",
    "next(iter(dict_wikidata_people.items())) #acces to both\n",
    "print(dict_wikidata_people.items())\n",
    "print(dict_wikidata_people)\n",
    "for q in dict_wikidata_people.items() :\n",
    "   # print(q)\n",
    "    print(q[0])\n",
    "    print(q[1]['genderlabel'])\n",
    "    print(q[1]['dob_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = '.../quotes-2018.json.bz2'\n",
    "path_to_out = '.../people_quotes-2018.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            qids = instance['qids'] # extracting list of qids\n",
    "            gender = []\n",
    "            dob = []\n",
    "            for qid in qids:\n",
    "                for qid_wiki in dict_wikidata_people.items() : \n",
    "                    if qid == qid_wiki[0] : \n",
    "                        gender = q[1]['genderlabel']\n",
    "                        dob = q[1]['dob_std']\n",
    "                        gender.append(gender)\n",
    "                        dob.append(dob)\n",
    "                    else :\n",
    "                        gender.append('None')\n",
    "                        dob.append('None')\n",
    "            instance['gender'] = gender # updating the sample with gender\n",
    "            instance['dob'] = dob # updating the sample with date of bith\n",
    "            d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
